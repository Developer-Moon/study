from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Dense
import numpy as np                          

#1. 데이터 
x = np.array([1,2,3])
y = np.array([1,2,3])


#2. 모델구성
model = Sequential()
model.add(Dense(5, input_dim=1, name='layer_1'))
model.add(Dense(3, name='layer_2'))
model.add(Dense(4, name='layer_3'))
model.add(Dense(2, name='layer_4'))
model.add(Dense(1, name='layer_5'))

model.summary() # 모델들의 계층 및 파라미터 인 아웃을 표현
                # 총 파라미터 개수 확인 가능 연산량 측정가능
                # bias는 node 1개에 해당
"""
Layer (type)                 Output Shape              Param #          입력노드와 출력노드 사이에 연결된 간선의 수      
=================================================================
layer_1 (Dense)              (None, 5)                 10                  
_________________________________________________________________
layer_2 (Dense)              (None, 3)                 18            
_________________________________________________________________
layer_3 (Dense)              (None, 4)                 16            
_________________________________________________________________
layer_4 (Dense)              (None, 2)                 10               
_________________________________________________________________
layer_5 (Dense)              (None, 1)                 3                  
=================================================================
Total params: 57
Trainable params: 57
Non-trainable params: 0

"""

'''
[데이터 전처리] - 전처리는 컬럼별로 해야한다 컬럼마다 내용이 다 다르니까 

전체데이터를 전처리 하지 않는다 그렇게되면 과적합에 걸린다
train데이터만 스케일링한다  범위 밖 값들은 상관없다 그 값들은 
테스트과 발리데이션은 트레인에 적용한 규칙들로 변환을 시킨다

스케일링은 전체 데이터에 적용하는 것이 아니라 트레인 데이터에 적용
이유는 테스트 데이터의 스케일러 범위 밖의 값(0미만 1이상) 으로 평가를 하면 좋기 때문





Feature Scaling - 모든 특성의 범위(또는 분포)를 같게 만들어주는 것
------------------------------------------------------------------------
StandardScaler()         
특성들의 평균을 0, 분산을 1 로 스케일링하는 것
즉, 특성들을 정규분포로 만드는 것
최솟값과 최댓값의 크기를 제한하지 않기 때문에, 어떤 알고리즘에서는 문제가 있을 수 있으며
이상치에 매우 민감
회귀보다 분류에 유용


------------------------------------------------------------------------
MinMaxScaler()
Min-Max Normalization 이라고도 불리며,
특성들을 특정 범위(주로 [0,1]) 로 스케일링 하는 것
가작 작은 값은 0, 가장 큰 값은 1 로 변환되므로, 모든 특성들은 [0, 1] 범위를 가짐

이상치에 매우 민감
분류보다 회귀에 유용


------------------------------------------------------------------------
MaxAbsScaler()
각 특성의 절대값이 0 과 1 사이가 되도록 스케일링
즉, 모든 값은 -1 과 1 사이로 표현되며, 데이터가 양수일 경우 MinMaxScaler 와 같다
이상치에 매우 민감



------------------------------------------------------------------------
RobustScaler()
평균과 분산 대신에 중간 값과 사분위 값을 사용
중간 값은 정렬시 중간에 있는 값을 의미하고
사분위값은 1/4, 3/4에 위치한 값을 의미
이상치 영향을 최소화할 수 있음
------------------------------------------------------------------------


Normalizer()
앞의 4가지 스케일러는 각 특성(열)의 통계치를 이용하여 진행
그러나 Normalizer 의 경우 각 샘플(행)마다 적용되는 방식
이는 한 행의 모든 특성들 사이의 유클리드 거리(L2 norm)가 1이 되도록 스케일링
일반적인 데이터 전처리의 상황에서 사용되는 것이 아니라
모델(특히나 딥러닝) 내 학습 벡터에 적용하며,
특히나 피쳐들이 다른 단위(키, 나이, 소득 등)라면 더더욱 사용하지 않는다




'''