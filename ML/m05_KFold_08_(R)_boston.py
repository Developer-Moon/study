from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, KFold
from sklearn.metrics import r2_score, accuracy_score
from sklearn.svm import SVR
import numpy as np
from sklearn.datasets import load_boston


#1. 데이터
datasets = load_boston()
x = datasets['data']
y = datasets['target']

x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8, random_state=9)
                      
n_splits = 5              
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=66)
                    
                                      
#2. 모델구성
model = SVR()


#3. 컴파일, 훈련, 평가, 예측
scores = cross_val_score(model, x_train, y_train, cv=kfold)               # cv=5 라면 kfold를 5로 쓴다
y_predict = cross_val_predict(model, x_test, y_test, cv=kfold)
r2 = r2_score(y_test, y_predict)

print('r2 :', scores, '\ncross_val_score :' , round(np.mean(scores), 4)) # 4번째까지 출력 (반올림을 5번째 자리에서)
print(y_predict)
print('cross_val_predict r2 : ', r2)

# r2 : [0.29026001 0.11248434 0.20205881 0.05979788 0.28013664] 
# cross_val_score : 0.1889
# [16.39579315 14.36062213 23.13982856 17.17462041 22.76625697 18.4633341
#  23.48048098 23.27809812 16.2696718  18.62582896 22.97769626 16.27354767
#  21.71963756 16.33688264 20.13972884 23.05524131 16.4186956  16.18737593
#  23.06360606 16.10902758 22.37196531 16.50823446 22.4882436  18.07557562
#  22.54107157 23.27642865 22.22128567 14.34851009 20.71246805 21.84084694
#  14.32668668 14.35091753 23.0836661  21.6075115  20.3494824  20.19382207
#  22.27714964 22.57022884 16.28117687 23.19485551 20.84446575 22.60654754
#  14.8628719  23.35056897 23.38959948 23.25599546 22.80968811 22.55028938
#  17.46990471 23.01342714 22.67406909 22.60882129 15.09311009 22.60710635
#  20.80095817 14.21025283 22.3908393  14.86495046 23.44306758 22.047039
#  22.41660379 21.91828081 16.30862278 14.28250408 23.15187998 22.1561973
#  22.0965158  22.30450045 14.29724841 21.83202634 22.74840551 17.46604103
#  22.64396353 22.16223993 16.48997102 22.51765268 20.23794633 23.26213575
#  20.46674407 16.11708582 16.58267107 22.18514105 22.44890251 20.35200602
#  20.48898612 22.36626696 22.24274659 15.25149205 21.91289676 17.46065457
#  20.50570115 15.60925183 21.5057588  22.40989202 21.45179814 22.80871995
#  22.02806852 20.87706282 23.29570463 19.88312531 22.70458317 22.67168769]        
# cross_val_predict r2 :  0.1666902224514255