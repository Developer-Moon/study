import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.decomposition import PCA
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.metrics import r2_score, accuracy_score
from sklearn.feature_selection import SelectFromModel
from sklearn.pipeline import make_pipeline
import matplotlib.pyplot as plt
import math
import time
import joblib as jb


# 1. 데이터
path = './_data/dacon_antena/'      
train = pd.read_csv(path + 'train.csv', index_col=0)
test = pd.read_csv(path + 'test.csv', index_col=0)

# print(train.head())
# print(train.info())
# print(train.isnull().sum())
# print(train.columns)

# 결측치 없음, 근데 뭐의 측정값의 0이 결측치란 얘기 있음
# x01~x56 / y01~y14


x = train.drop(['Y_01', 'Y_02', 'Y_03', 'Y_04', 'Y_05', 'Y_06', 'Y_07',
       'Y_08', 'Y_09', 'Y_10', 'Y_11', 'Y_12', 'Y_13', 'Y_14'], axis=1)

y_ = train.drop(['X_01', 'X_02', 'X_03', 'X_04', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09',
       'X_10', 'X_11', 'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18',
       'X_19', 'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27',
       'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36',
       'X_37', 'X_38', 'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45',
       'X_46', 'X_47', 'X_48', 'X_49', 'X_50', 'X_51', 'X_52', 'X_53', 'X_54',
       'X_55', 'X_56'],axis=1)

print(x.shape, y_.shape) # (39607, 56) (39607, 14)

xarr1 = np.array(x.drop(['X_16', 'X_17', 'X_18',
       'X_19', 'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27',
       'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36',
       'X_37', 'X_38', 'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45',
       'X_46', 'X_47', 'X_48', 'X_49', 'X_50', 'X_51', 'X_52', 'X_53', 'X_54',
       'X_55', 'X_56'], axis=1)) # 1~15

xarr2 = np.array(x.drop(['X_01', 'X_02', 'X_03', 'X_04', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10', 'X_11', 
       'X_12', 'X_13', 'X_14', 'X_15','X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36',
       'X_37', 'X_38', 'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45',
       'X_46', 'X_47', 'X_48', 'X_49', 'X_50', 'X_51', 'X_52', 'X_53', 'X_54',
       'X_55', 'X_56' ], axis=1)) # 16~30

xarr3 = np.array(x.drop(['X_01', 'X_02', 'X_03', 'X_04', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09','X_10', 'X_11',
       'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18',
       'X_19', 'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27',
       'X_28', 'X_29', 'X_30','X_46', 'X_47', 'X_48', 'X_49', 'X_50', 'X_51', 'X_52', 'X_53', 'X_54',
       'X_55', 'X_56'], axis=1)) # 31~45

xarr4 = np.array(x.drop(['X_01', 'X_02', 'X_03', 'X_04', 'X_05', 'X_06', 'X_07', 'X_08', 'X_09', 'X_10', 'X_11', 
       'X_12', 'X_13', 'X_14', 'X_15', 'X_16', 'X_17', 'X_18',
       'X_19', 'X_20', 'X_21', 'X_22', 'X_23', 'X_24', 'X_25', 'X_26', 'X_27',
       'X_28', 'X_29', 'X_30', 'X_31', 'X_32', 'X_33', 'X_34', 'X_35', 'X_36',
       'X_37', 'X_38', 'X_39', 'X_40', 'X_41', 'X_42', 'X_43', 'X_44', 'X_45'], axis=1)) # 46~56

x = x.drop(['X_10', 'X_11'], axis=1) # 결측치 있는 칼럼 제거
test = test.drop(['X_10', 'X_11'], axis=1)

def outliers(data_out):
    quartile_1, q2, quartile_3 = np.percentile(data_out, [25, 50, 75])

    print('1사분위: ', quartile_1)
    print('q2: ', q2)
    print('3사분위: ', quartile_3)
    iqr = quartile_3-quartile_1 # interquartile range
    lower_bound = quartile_1 - (iqr * 1.5)
    upper_bound = quartile_3 + (iqr * 1.5)
    return np.where((data_out>upper_bound) | (data_out<lower_bound))

def outliers_printer(dataset):
    plt.figure(figsize=(10,13))
    for i in range(dataset.shape[1]):
        col = dataset[:, i]
        outliers_loc = outliers(col)
        print(i, '열의 이상치의 위치: ', outliers_loc, '\n')
        plt.subplot(math.ceil(dataset.shape[1]/2),2,i+1)
        plt.boxplot(col)
        plt.title(i)
        
    plt.show()

where = outliers(x['X_25'])
# print(np.array(where))
# outliers_printer(xarr2)

x3 = [ 2181,  2184,  4490,  6896,  6901,  6902,  6912,  9178,  9184,
       11532, 11535, 11536, 13866, 14038, 14178, 14181, 14195, 14211,
       14212, 14213, 14243, 14244, 14257, 14261, 14262, 14263, 14267,
       14283, 14296, 14336, 14337, 14338, 14340, 14343, 14371, 14383,
       14409, 14421, 14423, 14425, 14430, 14437, 14445, 14457, 14458,
       14460, 14463, 14474, 14478, 14482, 14487, 14489, 14497, 14501,
       14502, 14505, 14513, 14527, 14529, 14531, 14533, 14534, 14536,
       14537, 14539, 14541, 14543, 14545, 14546, 14550, 14552, 14559,
       14561, 14575, 14576, 14577, 14578, 14580, 14581, 14584, 14588,
       14603, 14607, 14611, 14622, 14632, 14634, 14646, 14650, 14654,
       14655, 14656, 14657, 14659, 14660, 14662, 14665, 14673, 14674,
       14676, 14704, 14714, 14720, 14727, 14730, 14746, 14749, 14753,
       14760, 14761, 14762, 14763, 14764, 14765, 14766, 14768, 14774,
       14775, 14801, 14809, 18202, 18304, 18307, 18310, 18331, 18335,
       18352, 18358, 18369, 18380, 18392, 18393, 18406, 18408, 18415,
       18416, 18417, 18419, 18433, 18445, 18487, 18490, 18495, 18496,
       18501, 18511, 18518, 18536, 18539, 18542, 18550, 18563, 18576,
       18577, 18578, 18588, 18597, 18601, 18602, 18607, 18614, 18617,
       18619, 18623, 18626, 18628, 18629, 18634, 18635, 18636, 18638,
       18640, 18652, 18666, 18667, 18671, 18673, 18674, 18678, 18681,
       18683, 18695, 18708, 18709, 18710, 18711, 18719, 18720, 18726,
       18750, 18757, 18766, 18783, 18785, 18787, 18791, 18802, 18830,
       18831, 18832, 18833, 18836, 18844, 18861, 18863, 18867, 18875,
       18878, 18894, 18896, 18897, 18900, 18903, 18905, 18907, 18908,
       18909, 18943, 18945, 18948, 18951, 18953, 22428, 22450, 22546,
       22564, 22565, 22578, 22587, 22596, 22598, 22601, 22605, 22606,
       22611, 22628, 22630, 22639, 22640, 22656, 22657, 22661, 22662,
       22663, 22664, 22682, 22691, 22712, 22721, 22734, 22739, 22747,
       22751, 22763, 22764, 22778, 22781, 22782, 22783, 22807, 22814,
       22815, 22827, 22829, 22833, 22840, 22851, 22853, 22858, 22859,
       22862, 22868, 22874, 22878, 22880, 22881, 22885, 22896, 22898,
       22900, 22901, 22904, 22913, 22916, 22917, 22918, 22919, 22921,
       22926, 22928, 22932, 22947, 22948, 22949, 22950, 22951, 22953,
       22955, 22957, 22959, 22961, 22963, 22968, 22980, 22981, 22984,
       22991, 22993, 23002, 23012, 23023, 23033, 23036, 23037, 23051,
       23052, 23055, 23056, 23058, 23061, 23066, 23070, 23075, 23081,
       23110, 23111, 23114, 23115, 23116, 23117, 23118, 23121, 23123,
       23124, 23128, 23138, 23139, 23140, 23150, 23157, 23168, 23169,
       23171, 23172, 23174, 23175, 23178, 23179, 23180, 23181, 23183,
       23184, 23208, 23212, 23213, 23214, 23215, 23216, 23219, 26867,
       26869, 26890, 26892, 26905, 26924, 26925, 26927, 26942, 26953,
       26954, 26965, 26967, 26973, 26994, 27003, 27039, 27041, 27046,
       27048, 27055, 27066, 27075, 27077, 27080, 27087, 27088, 27094,
       27106, 27121, 27133, 27134, 27139, 27140, 27143, 27144, 27146,
       27148, 27150, 27153, 27158, 27161, 27171, 27172, 27173, 27188,
       27189, 27190, 27194, 27196, 27198, 27200, 27207, 27208, 27212,
       27213, 27243, 27245, 27247, 27248, 27250, 27251, 27253, 27258,
       27263, 27268, 27269, 27273, 27279, 27294, 27296, 27302, 27309,
       27311, 27320, 27324, 27331, 27337, 27341, 27350, 27355, 27360,
       27369, 27399, 27400, 27401, 27404, 27413, 27414, 27441, 27442,
       27446, 27447, 27455, 27460, 27463, 27466, 27467, 27468, 27508,
       27509, 27513, 27516, 27518, 29572, 30997, 31029, 31109, 31129,
       31141, 31151, 31153, 31155, 31159, 31160, 31162, 31163, 31193,
       31209, 31215, 31216, 31217, 31224, 31243, 31249, 31251, 31259,
       31300, 31304, 31305, 31313, 31317, 31327, 31328, 31340, 31341,
       31347, 31359, 31366, 31368, 31371, 31379, 31381, 31382, 31383,
       31385, 31386, 31387, 31396, 31404, 31407, 31412, 31417, 31420,
       31432, 31433, 31440, 31441, 31451, 31455, 31461, 31463, 31465,
       31469, 31477, 31480, 31483, 31495, 31496, 31500, 31502, 31503,
       31504, 31506, 31508, 31509, 31510, 31514, 31515, 31517, 31518,
       31523, 31525, 31526, 31527, 31528, 31536, 31538, 31540, 31541,
       31547, 31549, 31550, 31551, 31552, 31560, 31562, 31568, 31572,
       31573, 31574, 31586, 31609, 31610, 31611, 31613, 31614, 31615,
       31616, 31625, 31627, 31628, 31637, 31666, 31667, 31669, 31672,
       31675, 31678, 31686, 31692, 31699, 31709, 31722, 31723, 31725,
       31729, 31734, 31736, 31771, 31774, 31775, 31781, 31783, 35472,
       35477, 35479, 35500, 35501, 35514, 35523, 35535, 35539, 35540,
       35541, 35569, 35571, 35586, 35594, 35612, 35620, 35627, 35633,
       35634, 35635, 35674, 35677, 35678, 35679, 35680, 35694, 35697,
       35707, 35715, 35716, 35720, 35724, 35735, 35738, 35743, 35744,
       35745, 35753, 35758, 35765, 35786, 35787, 35798, 35799, 35806,
       35810, 35817, 35818, 35820, 35822, 35831, 35832, 35833, 35834,
       35835, 35836, 35850, 35860, 35865, 35866, 35867, 35869, 35875,
       35876, 35877, 35878, 35880, 35881, 35885, 35888, 35910, 35917,
       35934, 35952, 35956, 35969, 35970, 35973, 35984, 35986, 35988,
       35989, 35992, 35993, 35994, 35998, 36036, 36037, 36041, 36049,
       36055, 36062, 36065, 36076, 36095, 36096, 36097, 36103, 36106,
       36134, 36136, 36139, 36142, 36144, 36148]
x25 = np.array(outliers(x['X_25']))

x_ = np.array(x)
y_ = np.array(y_)

for i in range(len(x3)):
    x_[x3[i]][2] = x['X_03'].median() + 20
    
for i in range(len(x25)):
    x_[x25[i]][24] = 0

# 25~28 , 30


# '''
# 2. 모델
from sklearn.pipeline import make_pipeline
xgb = XGBRegressor(tree_method='gpu_hist', predictor='gpu_predictor', gpu_id=0, random_state=1234,
                   n_estimators=300, learning_rate=0.08, gamma = 0, subsample=0.75, colsample_bytree = 1, max_depth=7)
model = make_pipeline(MinMaxScaler(), xgb)

# 3. 컴파일, 훈련
model.fit(x_, y_)
# '''

path = './_data/dacon_antena/'  
jb.dump(model, path + 'antena.dat')
# model = jb.load(path + 'antena.dat')

# 4. 평가, 예측
results = model.score(x_, y_)
# y_pred = model.predict(x)
# r2 = r2_score(y_pred, test)
print('evaluate 결과: ', results)
# print('r2: ', r2)

# 5. 제출 준비
y_submit = model.predict(test)
submission = pd.read_csv(path+'sample_submission.csv', index_col=0)

for idx, col in enumerate(submission.columns):
    if col=='ID':
        continue
    submission[col] = y_submit[:,idx-1]
    
submission.to_csv(path + 'submission2.csv', index=True)


# evaluate 결과:  0.5424772577191542